# 基于elementUI的el-upload封装文件分片上传组件 

---
![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8b1e6691fe3842b0a13f932f5a6e7cc9~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?)



## 1\. 概念

文件分片的核心是利用Blod.prototype.slice方法，将文件切分为一个个的切片，借助 http 的可并发性，同时上传多个切片

## 2\. 实现

分片组件是基于elementUI的el-upload组件上的二次封装

```js
<template>
    <div>
        <el-upload class="uploadComponent" ref="uploadFile" :drag="!disabled"
            v-bind="$attrs" :on-change="handleUpload" :disabled="disabled"
        >
            <i class="el-icon-upload" v-show="!disabled"></i>
        </el-upload>
    </div>
</template>
```

通过属性透传v-bind=“$attrs”实现绑定在组件上的属性传递给el-upload组件，因此可以在组件上绑定el-upload组件已实现的属性

```js
<file-chunks-upload-component 
    :disabled="!isEdit" ref="videoUpload" :file-list="videoFileList"
    action="" :auto-upload="false" list-type="fileList"
    accept=".mp4, .avi, .wmv, .rmvb, .rm" validType="video"
    validTypeTip="上传文件只能是mp4, avi, wmv, rmvb格式"
    :getFileChunks="handleUpload" :sliceSize="100 * 1024 * 1024"
    :on-preview="handleVideoPreview" :before-remove="handleVideoRemove"
/>

```

组件除了接收el-upload组件的属性，还额外接收几个属性：

-   **disabled**：设置组件是否可编辑
-   **validType**：文件校验类型，单个检验类型的话可传入字符串，如’video’、’image’，多个检验类型的话可传入数组，如\[‘video’, ‘image’\]
-   **validTypeTip**：文件检验不通过时的提示文本
-   **chunkSize**：每个分片大小
-   **getFileChunks**：获取分片信息
-   **sliceSize**：启动文件分片的临界点

在el-upload组件上绑定on-change属性监听文件变化，拿到文件信息，进行一系列的处理

处理过程：

1.  判断文件大小是否大于sliceSize，是，则继续实现分片处理，否，则返回文件

```js
// 文件大小小于sliceSize时，不进行分片，直接返回文件
if(this.sliceSize && file.size <= this.sliceSize){
    this.getFileChunks && this.getFileChunks({file})
    return
}
```

2.  检验文件类型 通过文件头信息方式检验文件类型，封装成一个工具方法

```js
/***
 * 通过文件头信息方式检验文件类型
 * https://blog.csdn.net/tjcwt2011/article/details/120333846?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link
 */

const fileType = Object.assign(Object.create(null), {
    'isMP4': str => ['00 00 00 14', '00 00 00 18', '00 00 00 1c', '00 00 00 20'].some(s => str.indexOf(s) === 0),
    'isAVI': str => str.indexOf('52 49 46 46') === 0,
    'isWMV': str => str.indexOf('30 26 b2 75') === 0,
    'isRMVB': str => str.indexOf('2e 52 4d 46') === 0,
    'isJPG': str => str.indexOf('ff d8 ff') === 0,
    'isPNG': str => str.indexOf('89 50 4e 47') === 0,
    'isGIF': str => str.indexOf('47 49 46 38') === 0
})

const validFileType = Object.assign(Object.create(null), {
    'video': str => fileType['isMP4'](str) || fileType['isAVI'](str) ||  fileType['isWMV'](str) || fileType['isRMVB'](str),
    'image': str => fileType['isJPG'](str) || fileType['isPNG'](str) || fileType['isGIF'](str)
})

const bufferToString = async buffer => {
    let str = [...new Uint8Array(buffer)].map(b => b.toString(16).toLowerCase().padStart(2, '0')).join(' ')
    return str
}

const readBuffer = (file, start = 0, end = 4) => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader()
        reader.onload = () => {
            resolve(reader.result)
        }
        reader.onerror = reject
        reader.readAsArrayBuffer(file.slice(start, end))
    })
}

const validator = async (type, file) => {
    const buffer = await readBuffer(file)
    const str = await bufferToString(buffer)
    
    switch(Object.prototype.toString.call(type)){
        case '[object String]':
            return validFileType[type](str)
        case '[object Array]':
            return [...type].some(t => validFileType[t](str))
    }
}

export default validator
```

注：各种文件类型的文件头信息可从以下链接查询 [文件信息头对照表](https://link.juejin.cn/?target=https%3A%2F%2Fblog.csdn.net%2Ftjcwt2011%2Farticle%2Fdetails%2F120333846%3Futm_medium%3Ddistribute.pc_relevant.none-task-blog-2%257Edefault%257ECTRLIST%257Edefault-3.no_search_link%26depth_1-utm_source%3Ddistribute.pc_relevant.none-task-blog-2%257Edefault%257ECTRLIST%257Edefault-3.no_search_link "https://blog.csdn.net/tjcwt2011/article/details/120333846?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link")

3.  生成切片 利用blob.prototype.slice将大文件切分成一个一个的小片段

```js
createFileChunk(file){
    let chunks = []
    let cur = 0
    if(file.size > this.chunkSize){
        while(cur < file.size){
            chunks.push({ file: file.slice(cur, cur + this.chunkSize) })
            cur += this.chunkSize
        }
    }else{
        chunks.push({ file: file })
    }
    return chunks
},
```

4.  生成hash 为了实现断点续传、秒传的效果，需要前端生成一个唯一标识提供给后端，由于唯一标识必须保持不变，所以正确的做法是根据文件内容生成hash。这里需要用到一个库[spark-md5](https://link.juejin.cn/?target=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2Fspark-md5 "https://www.npmjs.com/package/spark-md5")，它可以根据文件内容计算出文件的hash值。

由于计算hash是非常耗费时间的，并且会引起 UI 的阻塞，所有这里使用web-worker在worker线程计算hash。由于实例化 web-worker 时，函数参数 `URL` 为指定的脚本且不能跨域，所以我们单独创建一个 hash.js 文件放在 public 目录下，然后通过importScripts 函数用于导入 spark-md5

hash.js

```js
// 引入spark-md5
self.importScripts('spark-md5.min.js')

self.onmessage = e=>{
  // 接受主线程传递的数据
  let { chunks } = e.data
  const spark = new self.SparkMD5.ArrayBuffer()

  let count = 0

  const loadNext = index=>{
    const reader = new FileReader()
    reader.readAsArrayBuffer(chunks[index].file)
    reader.onload = e=>{
      count ++
      spark.append(e.target.result)

      if(count==chunks.length){
        self.postMessage({
          hash:spark.end()
        })
      }else{
        loadNext(count)
      }
    }
  }
  loadNext(0)
}
```

**分片越多，分片越大，计算hash所耗费的时间就越久，为优化计算速度，在损失一定精度的情况下，采用抽样的方式计算hash**

这里分了两种情况

1.文件大小小于50M时，对所有的分片计算hash

2.文件大小大于50M时，以偶数位的方式抽取分片，并提取每个分片10M的内容去计算hash

计算hash方法

```js
 async calculateHashWorker(chunks, size){
    var _this = this;
    // 文件大小超过50M时，使用抽样方式生成hash
    const MAX_FILE_SIZE = 50 * 1024 * 1024
    const SAMPLE_SIZE = 10 * 1024 * 1024
    if(size >= MAX_FILE_SIZE){
        chunks = chunks.map((item, index) => {
            if(index % 2 == 0){
                return { file: item.file.slice(0, SAMPLE_SIZE)}
            }
        }).filter(item => item)
    }

    return new Promise(resolve => {
        _this.worker = new Worker('/hash.js')
        _this.worker.postMessage({ chunks })
        _this.worker.onmessage = e => {
            const { hash } = e.data
            if (hash) {
                resolve(hash)
            }
        }
    })
},
```

5.  返回文件切片信息 通过在组件上绑定getFileChunks属性获取到切片集合、hash值以及文件信息

```js
async handleUpload(params){
    if(!params.raw) return
    let file = params.raw
    // 文件大小小于sliceSize时，不进行分片，直接返回文件
    if(this.sliceSize && file.size <= this.sliceSize){
        this.getFileChunks && this.getFileChunks({file})
        return
    }
    // 校验文件类型
    if(this.validType && !await validator(this.validType, file)){
        this.$message({
            type: 'warning',
            message: this.validTypeTip,
            duration: 3000,
        })
        this.clearUploadFiles()
        return
    }

    const loading  = this.$loading({
        lock: true,
        text: '生成切片中，请耐心等候'
    })

    let chunks = this.createFileChunk(file)
    let hash = await this.calculateHashWorker(chunks, file.size)

    this.getFileChunks && this.getFileChunks({chunks, hash, file})

    loading.close()
},
```

分片上传组件完整代码

```js
<template>
    <div>
        <el-upload class="uploadComponent" ref="uploadFile" :drag="!disabled"
            v-bind="$attrs" :on-change="handleUpload" :disabled="disabled"
        >
            <i class="el-icon-upload" v-show="!disabled"></i>
        </el-upload>
    </div>
</template>

<script>
import validator from '@/utils/fileTypeValidate'

export default {
    name: 'FileChunksUploadComponent',
    props: {
        disabled: {  // 是否可编辑
            type: Boolean,
            default: false
        },
        validType: {  // 文件校验类型
            type: String | Array,
            default(){
                return ''
            }
        },
        validTypeTip: {  // 文件检验提示
            type: String,
            default: '上传文件格式不正确!'
        },
        chunkSize: {  // 分片大小
            type: Number,
            default: 50 * 1024 * 1024
        },
        getFileChunks: {  // 获取分片信息方法
            type: Function,
            default: null
        },
        sliceSize: {  // 文件实现分片的临界大小
            type: Number,
            default: 0
        }  
    },
    methods: {
        async handleUpload(params){
            if(!params.raw) return
            let file = params.raw
            // 文件大小小于sliceSize时，不进行分片，直接返回文件
            if(this.sliceSize && file.size <= this.sliceSize){
                this.getFileChunks && this.getFileChunks({file})
                return
            }
            // 校验文件类型
            if(this.validType && !await validator(this.validType, file)){
                this.$message({
                    type: 'warning',
                    message: this.validTypeTip,
                    duration: 3000,
                })
                this.clearUploadFiles()
                return
            }

            const loading  = this.$loading({
                lock: true,
                text: '生成切片中，请耐心等候'
            })
            
            let chunks = this.createFileChunk(file)
            let hash = await this.calculateHashWorker(chunks, file.size)

            this.getFileChunks && this.getFileChunks({chunks, hash, file})
            
            loading.close()
        },
        createFileChunk(file){
            let chunks = []
            let cur = 0
            if(file.size > this.chunkSize){
                while(cur < file.size){
                    chunks.push({ file: file.slice(cur, cur + this.chunkSize) })
                    cur += this.chunkSize
                }
            }else{
                chunks.push({ file: file })
            }
            return chunks
        },
        async calculateHashWorker(chunks, size){
            var _this = this;
            // 文件大小超过50M时，使用抽样方式生成hash
            const MAX_FILE_SIZE = 50 * 1024 * 1024
            const SAMPLE_SIZE = 10 * 1024 * 1024
            if(size >= MAX_FILE_SIZE){
                chunks = chunks.map((item, index) => {
                    if(index % 2 == 0){
                        return { file: item.file.slice(0, SAMPLE_SIZE)}
                    }
                }).filter(item => item)
            }

            return new Promise(resolve => {
                _this.worker = new Worker('/hash.js')
                _this.worker.postMessage({ chunks })
                _this.worker.onmessage = e => {
                    const { hash } = e.data
                    if (hash) {
                        resolve(hash)
                    }
                }
            })
        },
        clearUploadFiles(){
            this.$refs.uploadFile.clearFiles()
        }
    }
}
</script>
```

## 3\. 实战篇

为了实现大文件分片上传功能，需后台提供三个接口，包括分片检查接口、分片上传接口、分片合并接口。

-   **分片检查接口**：根据组件生成的hash值去检测是否有分片已上传过，文件是否已上传，实现中断续传，秒传的效果，避免文件重复上传。
-   **分片上传接口**：上传未上传过的分片
-   **分片合并接口**：文件全部分片上传完成，告知后台将分片合并成文件

分片合并过程是需要耗费一定的时间的，对于小文件来说，分片上传反而会增加上传时间，因此这里做了控制，在组件上绑定了sliceSize属性，控制文件小于100M时，组件只返回文件，直接调用文件上传接口。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57b8b383f49443d1b5efff636360e11e~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?)

## 3.1 分片上传流程

1.  调用分片检查接口，判断文件是否已上传或部分分片已上传

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dde9e88c329946c887c0c5be13dfd19c~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?) 2. 过滤掉已上传的分片，调用分片上传接口

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33427a4c9ab1444892f0636aae95336e~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?) 3. 所有分片上传完毕后，调用分片合并接口合并文件

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d262b1ed45a461a88fa79d4ed5dfed3~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?)

完整代码

```js
<file-chunks-upload-component 
    :disabled="!isEdit" ref="videoUpload" :file-list="videoFileList"
    action="" :auto-upload="false" list-type="fileList"
    accept=".mp4, .avi, .wmv, .rmvb, .rm" validType="video"
    validTypeTip="上传文件只能是mp4, avi, wmv, rmvb格式"
    :getFileChunks="handleUpload" :sliceSize="100 * 1024 * 1024"
    :on-preview="handleVideoPreview" :before-remove="handleVideoRemove"
/>
```

```js
async handleUpload({chunks, hash, file}){
    this.loading = true
    this.loadingText = '上传中，请耐心等候'
    try{
        let res = null
        if(chunks && hash){
            res = await this.sliceChunksUpload(chunks, hash, file)
        }else{
            res = await this.videoFileUpload(file)
        }
        if(res){
            this.videoFileList.push({name: res, url: res})
            this.$messageInfo('上传成功')
        }
    }catch(err){
        this.$messageWarn('上传失败')
    }

    this.$refs.videoUpload.clearUploadFiles()
    this.loading = false
    this.loadingText = ''
},
// 分片视频文件上传
sliceChunksUpload(chunks, hash, file){
    return new Promise(async (resolve, reject) => {
        chunks = chunks.map((item, index) => {
            return {
                file: item.file,
                name: `${index}_${hash}`,
                index,
                hash
            }
        })
        try{
            let {data} = await sewingCraftApi.checkChunkUpload({taskId: hash})
            if(data && data.completeUpload){
                resolve(data.uploadUrl)
                return
            }

            if(data.map){
                chunks = chunks.filter(({file, name}) => {
                    return !data.map[name] || data.map[name] != file.size
                })
            }

            if(chunks.length){
                let uploadRes = await httpUtil.multiRequest(chunks, uploadRequest)
                let flag = uploadRes.every(res => res.data)
                if(!flag){
                    reject('上传失败！')
                    return
                }
            }

            let extName = file.name.substring(file.name.lastIndexOf('.') + 1)
            sewingCraftApi.mergeChunk({taskId: hash, extName}).then(res => {
                resolve(res.data)
            })
        }catch(err){
            reject(err)
        }

        function uploadRequest({hash, index, name, file}){
            let formData = new FormData()
            formData.append('taskId', hash)
            formData.append('chunkNumber', index)
            formData.append('identifier', name)
            formData.append('file', file)
            return sewingCraftApi.uploadChunkUpload(formData)
        }
    })
}

```

## 引用

[字节跳动面试官：请你实现一个大文件上传和断点续传](https://juejin.cn/post/6844904046436843527#heading-17 "https://juejin.cn/post/6844904046436843527#heading-17")

[文件类型的终极校验](https://juejin.cn/post/6999241171566329887 "https://juejin.cn/post/6999241171566329887")

[128个常见的文件头信息对照表](https://link.juejin.cn/?target=https%3A%2F%2Fblog.csdn.net%2Ftjcwt2011%2Farticle%2Fdetails%2F120333846%3Futm_medium%3Ddistribute.pc_relevant.none-task-blog-2%257Edefault%257ECTRLIST%257Edefault-3.no_search_link%26depth_1-utm_source%3Ddistribute.pc_relevant.none-task-blog-2%257Edefault%257ECTRLIST%257Edefault-3.no_search_link "https://blog.csdn.net/tjcwt2011/article/details/120333846?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link")

## 文件切片

[谈谈前端大文件分片上传](https://juejin.cn/post/7044503613418242055)

- 为什么要切片？

一个文件过大，上传会非常的慢，而且还可能会中途失败导致前功尽弃。要重新上传文件，非常影响用户体验。文件切片以后，可以并发上传，速度比之前更快。而且如果中途失败可以做到不用上传已经上传过的。

- 对文件如何切片？

通过Blob.prototype.slice方法即可对文件进行切分，分片尽量不要太大，一般最大50M即可。

- 相关实现如下

```ini
const maxChunkSize = 52428800  // 最大容量块
const chunkSum = Math.ceil(file?.size / maxChunkSize)
                       
export const createFileChunks = async ({file, chunkSum, setProgress}) => {
  const fileChunkList = [];
  const chunkSize = Math.ceil(file?.size / chunkSum);
  let start = 0;
  for (let i = 0; i < chunkSum; i++) {
    const end = start + chunkSize;
    fileChunkList.push({
      index: i,
      filename: file?.name,
      file: file.slice(start, end)
    });
    start = end;
  }
  const result = await getFileHash({chunks: fileChunkList, setProgress});
  fileChunkList.map((item, index) => {
    item.key = result;
  });
  return fileChunkList;
};
```

## 计算文件hash

- 为什么要计算文件的hash？

通过对文件的内容进行一些算法加密运算得出文件的hash，文件的内容和hash是一一对应的。当我们修改文件内容时，hash就会变化。我们通过hash来判断是否是同一个文件。通过判别文件hash，可以知道哪些文件或者文件切片的已经上传完成。

- 如何计算文件的hash？

首先，我们上传的是一个大文件，所以计算文件的hash是非常的耗时的。我们都知道JS是单线程的，如果用来计算这么耗时的任务肯定是不妥的。解决方法有两个，如下

1、 通过Worker模拟JS多线程来处理耗时任务。

```ini
self.importScripts("https://cdn.bootcdn.net/ajax/libs/spark-md5/3.0.0/spark-md5.min.js");
self.onmessage = event => {
  console.log('worker接收的数据：',event.data)
  const chunks = event.data
  const spark = new self.SparkMD5.ArrayBuffer();
  const appendToSpark = async file => new Promise(resolve => {
      const reader = new FileReader();
      reader.readAsArrayBuffer(file);
      reader.onload = e => {
        console.log(e.target.result)
        spark.append(e.target.result);
        resolve();
      };
    });
  let count = 0;
  const workLoop = async () => {
    while (count < chunks.length) {
      await appendToSpark(chunks[count].file);
      count++;
      if (count >= chunks.length){
        self.postMessage(spark.end())
      } 
    }
  };
  workLoop()
}
复制代码
```

2、 在浏览器的空闲时间去计算文件的hash。

- 具体实现如下

```ini
export const getFileHash = async ({chunks, setProgress}) => new Promise(resolve => {
    const spark = new sparkMD5.ArrayBuffer();
    const appendToSpark = async file => new Promise(resolve => {
        const reader = new FileReader();
        reader.readAsArrayBuffer(file);
        reader.onload = e => {
          spark.append(e.target.result);
          resolve();
        };
      });
    let count = 0;
    const workLoop = async deadline => {
       // 块数没有计算完，并且当前帧还没结束
      while (count < chunks.length && deadline.timeRemaining() > 1) {
        await appendToSpark(chunks[count].file);
        count++;
        setProgress(Number(((100 * count) / chunks.length).toFixed(2)));
        if (count >= chunks.length) resolve(spark.end());
      }
      window.requestIdleCallback(workLoop);
    };
    window.requestIdleCallback(workLoop);
  });
复制代码
```

- 如何快速计算文件hash？

计算文件md5值的作用，无非就是为了判定文件是否存在，我们可以考虑设计一个抽样的hash，牺牲一些命中率的同时，提升效率，设计思路如下

1. 文件切成2M的切片
2. 第一个和最后一个切片全部内容，其他切片的取 首中尾三个地方各2个字节

1. 合并后的内容，计算md5，称之为影分身Hash
2. 这个hash的结果，有小概率误判。如果被抽样的样本都相同，而未被抽样的内容不同则会造成误判。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a187c0c2439a4c6fb8daa0bd03cfe6a1~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

```ini
 function createFileChunks({ file,setProgress }){
      const fileChunkList = [];
      const chunkSum = Math.ceil(file?.size / maxChunkSize)
      const chunkSize = Math.ceil(file?.size / chunkSum);
      let start = 0;
      for (let i = 0; i < chunkSum; i++) {
        const end = start + chunkSize;
        if(i == 0 || i == chunkSum - 1) {
          fileChunkList.push({
            index: i,
            filename: file?.name,
            file: file.slice(start, end),
          });
        } else {
          fileChunkList.push({
            index: i,
            filename: file?.name,
            file:sample(file,start,end),
          });
        }
        start = end;
      }
      return fileChunkList;
    };
		// 抽样函数
    function sample(file,start,end) {
      const pre = file.slice(start, start + 1024 * 2)
      const after = file.slice(end - 1024 * 2, end)
      const merge = new Blob([pre, after])
      return merge
    }
复制代码
```

## requestIdleCallback

window.requestIdleCallback()方法插入一个函数，这个函数将在浏览器空闲时期被调用。

页面是一帧一帧绘制出来的，当每秒绘制的帧数（FPS）达到 60 时，页面是流畅的，小于这个值时，用户会感觉到卡顿。1s 60帧，所以每一帧分到的时间是 1000/60 ≈ 16 ms。

- 浏览器一帧都做了啥？

1. 处理用户的交互
2. JS 解析执行
3. 帧开始。窗口尺寸变更，页面滚去等的处理
4. requestAnimationFrame(rAF)
5. 布局
6. 绘制

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5dca07521246427daf29798d31bcfc52~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)
![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3d4d29e6e214fc994d9c6f5a87a471d~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

就是说requestIdleCallback()会在一帧16ms中的最后执行，等到页面绘制完成以后看是否有空闲时间执行。如果有就执行，否则不执行。因为DOM已经绘制完成，所以不要在requestIdleCallback里面去操作DOM，这样容易引起会导致重新计算布局和视图的绘制，操作DOM建议在requestAnimationFrame中。

```ini
var handle = window.requestIdleCallback(callback[, options])
const cb = ({didTimeout, timeRemaining()}) => {}
const op = {timeout: 3000}
复制代码
```

- didTimeout 任务是否超时
- timeRemaining() 当前帧剩余的时间

- timeout 超时强制执行

详细见[requestIdleCallback](https://link.juejin.cn/?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FWindow%2FrequestIdleCallback)

## requestAnimationFrame

window.requestAnimationFrame() 告诉浏览器——你希望执行一个动画，并且要求浏览器在下次重绘之前调用指定的回调函数更新动画。该方法需要传入一个回调函数作为参数，该回调函数会在浏览器下一次重绘之前执行。

requestAnimationFrame 方法不同与 setTimeout 或 setInterval，它是由系统来决定回调函数的执行时机的，会请求浏览器在下一次重新渲染之前执行回调函数。无论设备的刷新率是多少，requestAnimationFrame 的时间间隔都会紧跟屏幕刷新一次所需要的时间；

setTimeout 做动画可能会卡顿，因为js是单线程的，如果前面的任务阻塞了，那么setTimeout 就会等之前的任务执行完成在执行，造成卡顿。

详细见[requestAnimationFrame](https://link.juejin.cn/?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FWindow%2FrequestAnimationFrame)

## 并发上传

通过Promise.all()可以并发上传所有的切片，并发上传所有切片可能会导致网络请求被全部占用，而且这样上传的成功率也会大打折扣。控制切片上传的并发数来解决此问题。

1、通过mapLimit来控制并发数

详情见[链接](https://link.juejin.cn/?target=https%3A%2F%2Fcaolan.github.io%2Fasync%2Fv3%2Fdocs.html%23mapLimit)

```javascript
npm install --save async
import mapLimit from 'async/mapLimit';
export const uploadChunks = ({
  chunks,
  url,
  chunkSum,
  limit,
  setProgress
}) => new Promise((resolve, reject) => {
    mapLimit(
      chunks,
      limit,
      ({index, key, filename, file}, cb) => {
        const formData = new FormData();
        formData.append('slice', index);
        formData.append('guid', key);
        formData.append('slices', chunkSum);
        formData.append('filename', filename);
        formData.append('file', file);
        request({
          url,
          data: formData,
          onProgress: e => {
            setProgress(parseInt(String((e.loaded / e.total) * 100)), index);
          },
          cb
        });
      },
      (err, result) => {
        if (err) {
          Message.error('文件上传出错,请检查以后重新上传')
          reject(err)
          return
        }
        resolve(result)
      }
    )
  });
复制代码
```

## 切片上传进度

切片的上传进度是通过XMLHttpRequest的upload.onprogress事件去监听。

```ini
export const request = ({
  url,
  method = 'post',
  data,
  headers = {},
  cb = e => e,
  onProgress = e => e
}) => {
    const xhr = new XMLHttpRequest();
    xhr.withCredentials = true
    xhr.timeout = 1000 * 60 * 60
    xhr.upload.onprogress = onProgress;
    xhr.open(method, url);
    headers = Object.assign({}, headers, {'EDR-Token': Cookie.get('auth')})
    Object.keys(headers).forEach(key => xhr.setRequestHeader(key, headers[key])
    );
    xhr.send(data);
    xhr.onload = e => {
      cb(null, {
        data: JSON.parse(e.target.response)
      });
    };
    xhr.onerror = error => {
      cb(error)
    }
  }
复制代码
```

## 切片合并与断点续传

当所有的切片都上传成功之后，我们就会向后端发起合并切片的请求。

如果切片上传到一半就发生了故障或者无网络了怎么办？要重新上传所有的切片吗？

不用，我们只要上传我们还没上传的切片就好。通过localStorage记录切片上传的信息或者每次在上传切片前向后台询问该切片是否已经上传。具体流程如下

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/266149a506ca462a9dec64842dd54281~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

## 总结

1. 计算文件的hash是为了判断文件的唯一性，通过hash也可以判断文件是否已经上传成功。
2. 文件的切片是通过Blob.prototype.slice去切分文件，切片是否上传成功的判断可以在服务的处理也可以在前端保留已上传切片的信息。

1. 计算文件的hash是一个非常耗时的任务，可以通过worker模拟多线程去处理，或者在浏览器的空闲时间requestIdleCallback去处理这个耗时的任务。为了快速的计算出文件的hash，也可以通过抽样的方式。
2. 文件的实时上传进度可以通过XMLHttpRequest的upload.onprogress去处理，也可以通过websocket去实时监听。

1. 所有切片都上传成功时，发起合并请求，让所有的切片合并成一个大文件。
